# Transformer

Transformer 的核心思想是通过**自注意力机制（Self-Attention）**和**多层堆叠的神经网络**进行语言建模。
 
先不管这些高大上的算法词汇，先用技术上宏观梳理数据流，
那么，基于 Transformer 构建文本生成的核心数据流是什么？

输入是一个字符串，比如'北京位于'，输出这是这个字符串后可能的字的概率，比如 '北'：20%，'京': 10%。

如何做到求概率，第一步当然是量化这些字符。

**首先**我们要把用户的输入（问题） `string` 进行切片，切片之后叫做 token，有可能是单词，也有可能只是单词的片段（to, world, meta...），对于视频和图片而言，tokens可能代表一小块图片或者一小段语音，而每个token对应一个向量，也就是一组数字。
\\[
to = \begin{bmatrix}
1.2 \\
0.1 \\
0.3 \\
... \\
2.3
\end{bmatrix}
\\]

我们把这个过程叫做 `Embedding`。
\\[ vector = Embedding(token) \\]

如何构建`Embedding`，我们的目标是要让该向量，代表字符的意义（向量就是意义），这种向量可以想象为高维空间的点，字符(token)之间越相似，那么向量在空间中就会越接近。

\\[E(雌) \approx E(雄) + E(女) - E(男)\\]

那么如何编码token的？又是如何确定维度的（GPT-3有12288个维度）？

模型有预设的词汇库（~50k），**Embedding Matrix**，就是每个词都对应一个向量, 
\\( W_E \\) 也是用数据驱动训练出来的，如何做到？


有了数字，才能做计算。

一个输入字符串，\\( [北, 京, 位, 于] \\) 会被描述为一个二维的数组（上下文长度，GPT: 2048）。
**接着**输入到**注意力机制模块**模型中，该模型允许向量（token）之间进行相互约束，来重新更新每个向量，
为什么要这么做，因为一个词在不同的语境下应该有不同的含义（**含义就是向量*）。比如 `问问题` 中的两个 `问`显然不是一个意思，
因此需要根据上下文，更新向量，也就是说，上下文的向量会拉扯当前的向量，使得它指向新的方向。

**然后**将更新后的每个向量，输入到**多层感知机**中，向量之间没关系，这是在提取每个字符本身的含义（这是中文吗，这是一个动词吗？这是数字吗？输出的维度暗含了我们考虑的方面有多少）。

**然后重复之前的过程**

Attention -> Preception -> Attention -> Preception -> ... ->

最后的目的，是将整个字符串的所有关键含义在最后一个向量中表达出来。

然后再对最后一个向量作为输入，与**Unembedding Matrix**相乘（类似每一个词与最后一个向量的相识度），
再进行归一化处理，得到所有token的概率分布。

\\[ W_U \times x_{out} = y_{out}\\]

## 自注意力机制

那么什么是自注意力机制？


## 多层堆叠的神经网络

