# MCP
​MCP（模型上下文协议，Model Context Protocol）是由 Anthropic 于 2024 年 11 月推出的开放标准，旨在统一大型语言模型（LLM）与外部数据源和工具之间的通信协议。

说人话，这是提供了大模型工具的一个远程调用协议。在我们实现 `function calling` 的时候，会把 `function` 的信息以一种固定的文本格式内嵌到提示词里面，和问题打包一起传给大模型。从工程化的角度来看，有几个问题要解决。

- 每次增加 `function` 的时候，不要改整个 `agent` 逻辑，这里可以用 `python` 的装饰器，把函数的注释信息自动抽取处理（函数名、详细描述、参数类型、参数含义、是否必须等等），存在一个全局变量中`TOOLS`，在生成提示词的时候，根据 `TOOLS` 去动态生成，这样 增加 `function` 就很容易了。
- `TOOLS` 以怎样的格式，嵌入到提示词中，大模型对工具（什么时候该调用）和对应的参数识别会更加准确率（React）？
  
 `function calling` 是在一个程序包中实现的（`TOOLS` 作为一个全局变量），MCP 的出现，通过 `http API`，帮我们进一步解耦 `function` 的开发 和 `agent` 开发。 也就是后台用 `python` 开发的工具，可以用 `js` 调用。那么MCP 的服务器端，应该会提供 工具的描述信息（函数名、详细描述、参数类型、参数含义、是否必须等等）。 MCP的客户端，应该有一种约束，能够很方便的把工具的信息注入到提示词中，同时把工具的结果以一种通用的方式再次注入到提示词中，再次注入到提示词，根据大模型返回最后的回答。

  
## 架构
1. 客户端程序，捕获用户问题（string），调用LLM（应该需要描述有哪些MCP server、本地的工具），LLM 会根据用户的问题，判断是否需要调用工具，并分析出工具。
2. 远超调用MCP server，获取结果；
3. 把结果放到提示词里面，在给到大模型
4. 大模型返回最后的回答。

## 注意
1. 客户端为什么知道MCP是多少的，有哪些工具，在第一次调用LLM前，应该先调用 MCP server，获取了工具的种类。
2. 关键是 MCP的信息，如何注入到提示词中，以及MCP返回的信息，如何注入到提示词中？
3. 还有MCP提供的协议具体规定了 json 的哪些内容？
